# -*- coding: utf-8 -*-
"""cancer-prediction-dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f7_3d7QIDGv2wmeQeeS396KJGvc8pPXV

# **The main question about the project is:**




## **What is the main objective of the project?**




### ''To create models capable of predicting with maximum accuracy whether a patient is likely to have cancer or not."

To achieve this, I used some well-known libraries listed below, aiming to achieve the best accuracy in my models.

_____________________________________________________________
"""

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split , StratifiedKFold, cross_val_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
import plotly.express as px

"""To perform the predictions and to handle the data, I used the main Python libraries: Scikit-learn, Pandas, Matplotlib, Numpy, Seaborn."""

plt.style.use('dark_background')
warnings.simplefilter('ignore', category=FutureWarning)



patients_data = pd.read_csv("/kaggle/input/cancer-prediction-dataset/The_Cancer_data_1500_V2.csv")
patients_data.head(10)

"""### **Dataset Structure**

**Features**


Age: Integer values representing the patient's age, ranging from 20 to 80.

Gender: Binary values representing gender, where 0 indicates Male and 1 indicates Female.

BMI: Continuous values representing Body Mass Index, ranging from 15 to 40.

Smoking: Binary values indicating smoking status, where 0 means No and 1 means Yes.

GeneticRisk: Categorical values representing genetic risk levels for cancer, with 0 indicating Low, 1 indicating Medium, and 2 indicating High.

PhysicalActivity: Continuous values representing the number of hours per week spent on physical activities, ranging from 0 to 10.

AlcoholIntake: Continuous values representing the number of alcohol units consumed per week, ranging from 0 to 5.

CancerHistory: Binary values indicating whether the patient has a personal history of cancer, where 0 means No and 1 means Yes.

Diagnosis: Binary values indicating the cancer diagnosis status, where 0 indicates No Cancer and 1 indicates Cancer

### **Data processing**

_____________________________________________________________

To achieve better precision I rounded some values ​​that had several decimal places to the nearest whole number

_____________________________________________________________
"""

patients_data[['AlcoholIntake','BMI','PhysicalActivity']] = patients_data[['AlcoholIntake','BMI','PhysicalActivity']].round(0)
patients_data.head(15)

"""_____________________________________________________________

Below I created some columns with average values ​​from the BMI, AGE, Physical Activity and Alcohol Intake columns

This improves the accuracy of learning methods

_____________________________________________________________
"""

patients_data['Age main'] = np.where(patients_data['Age'] < 50, '<50', '>=50')
patients_data['BMI main'] = np.where(patients_data['BMI'] < 27, '<27', '>=27')
patients_data['PhysicalActivity main'] = np.where(patients_data['PhysicalActivity'] < 5, '<5', '>=5')
patients_data['AlcoholIntake main'] = np.where(patients_data['AlcoholIntake'] < 2, '<2', '>=2')

patients_data.head(15)

patients_data.columns

new_order = ['Age', 'Gender', 'BMI', 'Smoking', 'GeneticRisk', 'PhysicalActivity',
       'AlcoholIntake', 'CancerHistory', 'Age main', 'BMI main',
       'PhysicalActivity main', 'AlcoholIntake main', 'Diagnosis']

patients_data = patients_data[new_order]
patients_data.head(15)

"""_____________________________________________________________

An important piece of information that can impact the final result is null attributes and, in this case, there were none.

_____________________________________________________________
"""

missing_values_per_column = patients_data.isna().sum()
print(missing_values_per_column)

patients_data.describe().T

"""_____________________________________________________________

### **Generating graphs for analysis**
"""

patients_data.columns

mean_age = patients_data['Age'].mean()

mean_diagnosis = patients_data['Diagnosis'].mean()


plt.figure(figsize=(8, 6))



sns.scatterplot(x='Age', y='Diagnosis', data=patients_data)

sns.lineplot(x='Age', y='Diagnosis', data=patients_data, marker='o')



plt.axhline(mean_diagnosis, color='red', linestyle='--', label=f'Média de Diagnosis: {mean_diagnosis:.2f}')

plt.xlabel('Eixo X (Age)')
plt.ylabel('Eixo Y (Diagnosis)')
plt.title('Gráfico Age por Diagnosis com Linha de Média')
plt.grid(True)
plt.legend()


plt.show()

"""_____________________________________________________________

Through the graph above, we can see that the patient's age is an extremely important factor that directly affects the analysis,
It is possible to see that the probability of people over 50 years of age having cancer is greater than that of people under 50 years of age.

Below I drew a parallel using the 'Sankey chart' among other variables that are commonly used to predict whether or not a patient is likely to have cancer, which are:

alcohol consumption and smokers

_____________________________________________________________
"""

grafico = px.parallel_categories(
    patients_data,
    dimensions=[ 'Age main','Smoking', 'AlcoholIntake' ],
    color='Diagnosis'
)
grafico.show()

"""_____________________________________________________________

I repeated the process again, but using other variables, also using age as a base

_____________________________________________________________
"""

grafico = px.parallel_categories(
    patients_data,
    dimensions=[ 'Age main','CancerHistory', 'GeneticRisk' ],
    color='Diagnosis'
)

grafico.show()

"""### **Predictions and Classes**"""

patients_data.shape

x_diagnostic = patients_data.iloc[ : , 0:12].values
y_diagnostic = patients_data.iloc[ : ,12].values
x_diagnostic

y_diagnostic

x_diagnostic.shape

label_patients = LabelEncoder()
x_diagnostic[:,8] = label_patients.fit_transform(x_diagnostic[:,8])
x_diagnostic[:,9] = label_patients.fit_transform(x_diagnostic[:,9])
x_diagnostic[:,10] = label_patients.fit_transform(x_diagnostic[:,10])
x_diagnostic[:,11] = label_patients.fit_transform(x_diagnostic[:,11])


x_diagnostic

OneHotEncoder = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0,1,2,3,4,5,6,7,8,9,10,11])], remainder='passthrough')
x_diagnostic = OneHotEncoder.fit_transform(x_diagnostic).toarray()
x_diagnostic

x_diagnostic.shape

scaler = StandardScaler()
x_diagnostic = scaler.fit_transform(x_diagnostic)
x_diagnostic

"""### **training dataset X test dataset**"""

diagnostic_X_train, diagnostic_X_test, diagnostic_y_train, diagnostic_y_test = train_test_split(x_diagnostic, y_diagnostic, test_size = 0.25, random_state = 0)

"""_____________________________________________________________________________________________________________________________________________________

## **Testing the model**

_____________________________________________________________________________________________________________________________________________________

### **Decision tree - 85,86%**
"""

tree_diagnostic = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
tree_diagnostic.fit(diagnostic_X_train, diagnostic_y_train)

predict_diagnostic = tree_diagnostic.predict(diagnostic_X_test)

accuracy_diagnostic = accuracy_score(diagnostic_y_test, predict_diagnostic)
accuracy_diagnostic

treecm_diagnostic = confusion_matrix(diagnostic_y_test,predict_diagnostic)
treecm_diagnostic

cm = confusion_matrix(diagnostic_y_test, predict_diagnostic)


sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predição')
plt.ylabel('Real')
plt.title('Matriz de Confusão do para o arvore de decisão')
plt.show()

plt.figure(figsize=(20,10))
tree.plot_tree(tree_diagnostic)
plt.show()

"""### **Random Forest - 89,33% **"""

random_forest_diagnostic = RandomForestClassifier(n_estimators = 60, criterion = 'entropy', random_state = 0)
random_forest_diagnostic.fit(diagnostic_X_train, diagnostic_y_train)

forest_predict_diagnostic = random_forest_diagnostic.predict(diagnostic_X_test)

diagnostic_accuracy = accuracy_score(diagnostic_y_test, forest_predict_diagnostic)
diagnostic_accuracy

cm_random = confusion_matrix(diagnostic_y_test, forest_predict_diagnostic)

sns.heatmap(cm_random, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predição')
plt.ylabel('Real')
plt.title('Matriz de Confusão do para o Random Forest')
plt.show()

"""### **Logistic regression -  94,93%**"""

logistic_diagnostic = LogisticRegression(random_state = 1)
logistic_diagnostic.fit(diagnostic_X_train, diagnostic_y_train)

logistic_diagnostic.intercept_

logistic_diagnostic.coef_

previsoes_diagnostic = logistic_diagnostic.predict(diagnostic_X_test)
accuracy_diagnostic = accuracy_score(diagnostic_y_test, previsoes_diagnostic)
accuracy_diagnostic

cm_logistic = confusion_matrix (diagnostic_y_test, previsoes_diagnostic)

sns.heatmap(cm_logistic, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predição')
plt.ylabel('Real')
plt.title('Matriz de Confusão do para o Random Forest')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(diagnostic_y_test, previsoes_diagnostic))

"""### **SVM - 93,33%**"""

svm_diagnostic = SVC(kernel = 'sigmoid', random_state = 0, C=1.0, gamma=0.01) #kernel : linear,poly,rbf,sigmoid
svm_diagnostic.fit(diagnostic_X_train, diagnostic_y_train) #

previsoes_diagnostic= svm_diagnostic.predict(diagnostic_X_test)

accuracy_diagnostic = accuracy_score(diagnostic_y_test, previsoes_diagnostic)
accuracy_diagnostic

cm_svc = confusion_matrix(diagnostic_y_test, previsoes_diagnostic)

sns.heatmap(cm_svc, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predição')
plt.ylabel('Real')
plt.title('Matriz de Confusão do para o SVC')
plt.show()

# Define models for evaluation
models = {
    'Logistic Regression(%)': [94.93],
    'Decision Tree(%)': [85.86],
    'Random Forest %)': [89.33],
    'SVM(%)': [93.33]

}

results_df = pd.DataFrame(models)

results_df